---
title: INF0613 -- Aprendizado de Máquina Não Supervisionado
output: pdf_document
subtitle: Trabalho 3 - Técnicas de Agrupamento
author: 
  - Evandro Santos Rocha
  - Laíssa Pacheco de Oliveira
  - Rafael Dantas de Moura
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, error = FALSE, message = FALSE, warning = FALSE, tidy = FALSE)
options(digits = 3)
```


O objetivo deste trabalho é exercitar o uso de algoritmos de agrupamento. Neste trabalho, vamos analisar diferentes atributos de carros com o objetivo de verificar se seus atributos são suficientes para indicar um valor de risco de seguro. O conjunto de dados já apresenta o risco calculado no campo `symboling` indicado na Tabela 1. Quanto mais próximo de 3, maior o risco. O conjunto de dados que deve ser usado está disponível na página do Moodle com o nome `imports-85.data`.

# Atividade 0 -- Configurando o ambiente
Antes de começar a implementação do seu trabalho configure o _workspace_ e importe todos os pacotes e execute o preprocessamento da base:

```{r atv0-code}
# Adicione os pacotes usados neste trabalho:
library(datasets)
library(mlbench)
library(caret)
library(ggplot2)

library(cluster)
library(factoextra)
library(NbClust)

library(dbscan)

# Configure ambiente de trabalho na mesma pasta 
# onde colocou a base de dados:
# setwd("")


```



# Atividade 1 -- Análise e Preparação dos Dados

O conjunto de dados é composto por 205 amostras com 26 atributos cada descritos na Tabela 1. Os atributos são dos tipos `factor`, `integer` ou  `numeric`. O objetivo desta etapa é a análise e preparação desses dados de forma a ser possível agrupá-los nas próximas atividades. 

**Implementações:** Nos itens a seguir você implementará a leitura da base e aplicará tratamentos básicos.

a) *Tratamento de dados Incompletos:* Amostras incompletas deverão ser tratadas, e você deve escolher a forma que achar mais adequada. Considere como uma amostra incompleta uma linha na qual faltam dados em alguma das colunas selecionadas anteriormente. Note que, dados faltantes nas amostras podem causar uma conversão do tipo do atributo de todas as amostras e isso pode impactar no item b). 

```{r atv1a-code}
# Leitura da base
#carros <- read.table(file.choose(), sep=",")
carros <- read.table("imports-85.data", sep=",")
summary(carros)
dim(carros)
#[1] 205  26

# Tratamento de dados faltantes
any(is.na(carros)) # verifica se há algum valor NA no conjunto de dados
# FALSE

# Verificando quais são os valores não numéricos de cada campo 
# que deveria vir como numérico no summary (de acordo com o enunciado)
carros[is.na(as.numeric(carros$V2)),]$V2      # possui 41 valores iguais "?" ---> retirar a feature
carros[is.na(as.numeric(carros$V19)),]$V19
carros[is.na(as.numeric(carros$V20)),]$V20
carros[is.na(as.numeric(carros$V22)),]$V22
carros[is.na(as.numeric(carros$V23)),]$V23
carros[is.na(as.numeric(carros$V26)),]$V26

# Encontrando valores iguais a "?" e substituindo por NA
carros$V2[which(carros$V2 == "?")] <- NA
carros$V19[which(carros$V19 == "?")] <- NA
carros$V20[which(carros$V20 == "?")] <- NA
carros$V22[which(carros$V22 == "?")] <- NA
carros$V23[which(carros$V23 == "?")] <- NA
carros$V26[which(carros$V26 == "?")] <- NA

# Conversão do tipo dos atributos
carros$V2 <- as.numeric(carros$V2)
carros$V19 <- as.numeric(carros$V19)
carros$V20 <- as.numeric(carros$V20)
carros$V22 <- as.numeric(carros$V22)
carros$V23 <- as.numeric(carros$V23)
carros$V26 <- as.numeric(carros$V26)

# Verificando se todos os campos numéricos estão ok
summary(carros)

# Atributo V2 possui muitos NAs, então resolvemos retirá-lo
carros$V2 <- NULL

# Tratamento de NA: será atribuída a média
carros$V19[is.na(carros$V19)] <- mean(carros$V19, na.rm = TRUE)
carros$V20[is.na(carros$V20)] <- mean(carros$V20, na.rm = TRUE)
carros$V22[is.na(carros$V22)] <- mean(carros$V22, na.rm = TRUE)
carros$V23[is.na(carros$V23)] <- mean(carros$V23, na.rm = TRUE)
carros$V26[is.na(carros$V26)] <- mean(carros$V26, na.rm = TRUE)

# Verificando se sobraram NAs
any(is.na(carros))

# Checando o summary novamente
summary(carros)
dim(carros)
#[1] 205  25

```

b) *Seleção de Atributos:* Atributos não-numéricos não podem ser usados com as técnicas  agrupamento vistas em aula. Portanto, você deve selecionar um conjunto de atributos numéricos que serão usados para o agrupamento. Além disso você deve analisar se os atributos não-numéricos são descritivos para a realização dos agrupamentos. Caso um dos atributos não numéricos seja necessário, use a técnica do  *one hot encoding* para transformá-lo em numérico. **Não** aplique essa técnica nos atributos `symboling` e `make` para os agrupamentos subsequentes, eles não devem fazer parte do agrupamento. 

```{r atv1b-code}

####################################
# Transformação em one-hot-encoding
####################################

#fuel-type
unique(carros$V4)
#[1] "gas"    "diesel"
carros$V4_gas    <- as.numeric(carros$V4 == "gas")
carros$V4_diesel <- as.numeric(carros$V4 == "diesel")
carros$V4 <- NULL

#aspiration
unique(carros$V5)
#[1] "std"   "turbo"
carros$V5_std   <- as.numeric(carros$V5 == "std")
carros$V5_turbo <- as.numeric(carros$V5 == "turbo")
carros$V5 <- NULL

#num-of-doors
unique(carros$V6)
#table(carros$V6)
#   ? four  two 
#   2  114   89
#[1] "two"  "four" "?"
carros$V6_two  <- as.numeric(carros$V6 == "two")
carros$V6_four <- as.numeric(carros$V6 == "four" | carros$V6 == "?")
carros$V6 <- NULL

#body-style
unique(carros$V7)
#[1] "convertible" "hatchback"   "sedan"       "wagon"       "hardtop"
carros$V7_convertible <- as.numeric(carros$V7 == "convertible")
carros$V7_hatchback   <- as.numeric(carros$V7 == "hatchback")
carros$V7_sedan       <- as.numeric(carros$V7 == "sedan")
carros$V7_wagon       <- as.numeric(carros$V7 == "wagon")
carros$V7_hardtop     <- as.numeric(carros$V7 == "hardtop")
carros$V7 <- NULL

#drive-wheels
unique(carros$V8)
#[1] "rwd" "fwd" "4wd"
carros$V8_rwd <- as.numeric(carros$V8 == "rwd")
carros$V8_fwd <- as.numeric(carros$V8 == "fwd")
carros$V8_4wd <- as.numeric(carros$V8 == "4wd")
carros$V8 <- NULL

#engine-location
unique(carros$V9)
#[1] "front" "rear"
carros$V9_front <- as.numeric(carros$V9 == "front")
carros$V9_rear  <- as.numeric(carros$V9 == "rear")
carros$V9 <- NULL

#engine-type
unique(carros$V15)
#[1] "dohc"  "ohcv"  "ohc"   "l"     "rotor" "ohcf"  "dohcv"
carros$V15_dohc  <- as.numeric(carros$V15 == "dohc")
carros$V15_ohcv  <- as.numeric(carros$V15 == "ohcv")
carros$V15_ohc   <- as.numeric(carros$V15 == "ohc")
carros$V15_l     <- as.numeric(carros$V15 == "l")
carros$V15_rotor <- as.numeric(carros$V15 == "rotor")
carros$V15_ohcf  <- as.numeric(carros$V15 == "ohcf")
carros$V15_dohcv <- as.numeric(carros$V15 == "dohcv")
carros$V15 <- NULL

#num-of-cylinders
unique(carros$V16)
#[1] "four"   "six"    "five"   "three"  "twelve" "two"    "eight"
carros$V16_four   <- as.numeric(carros$V16 == "four")
carros$V16_six    <- as.numeric(carros$V16 == "six")
carros$V16_five   <- as.numeric(carros$V16 == "five")
carros$V16_three  <- as.numeric(carros$V16 == "three")
carros$V16_twelve <- as.numeric(carros$V16 == "twelve")
carros$V16_two    <- as.numeric(carros$V16 == "two")
carros$V16_eight  <- as.numeric(carros$V16 == "eight")
carros$V16 <- NULL

#fuel-system
unique(carros$V18)
#[1] "mpfi" "2bbl" "mfi"  "1bbl" "spfi" "4bbl" "idi"  "spdi"
carros$V18_mpfi <- as.numeric(carros$V18 == "mpfi")
carros$V18_2bbl <- as.numeric(carros$V18 == "2bbl")
carros$V18_mfi  <- as.numeric(carros$V18 == "mfi")
carros$V18_1bbl <- as.numeric(carros$V18 == "1bbl")
carros$V18_spfi <- as.numeric(carros$V18 == "spfi")
carros$V18_4bbl <- as.numeric(carros$V18 == "4bbl")
carros$V18_idi  <- as.numeric(carros$V18 == "idi")
carros$V18_spdi <- as.numeric(carros$V18 == "spdi")
carros$V18 <- NULL


# Verificação de duplicados
dim(carros)
#[1] 205  54
dim(unique(carros))
#[1] 205  54
# RESULTADO: não há observações duplicadas

#########################
# Seleção de atributos
#########################

carros_atributos <- carros[,3:length(carros)] 

#Agora vem a seleção dos atributos
matriz_corr <- cor(carros_atributos)
#print(matriz_corr)

altamente_corr <- findCorrelation(matriz_corr, cutoff = 0.5)
print(altamente_corr)
#[1]  5  2 10  3  1 13  6 12 14 26 27 45 38 15 16 51  4 22 19 20 17 29  8 35 50

# atributos que estão altamente correlacionados e que podem ser excluídos
names(carros_atributos[altamente_corr])
# [1] "V14"          "V11"          "V22"          "V12"          "V10"          "V25"         
# [7] "V17"          "V24"          "V26"          "V8_rwd"       "V8_fwd"       "V18_mpfi"    
#[13] "V16_four"     "V4_gas"       "V4_diesel"    "V18_idi"      "V13"          "V7_hatchback"
#[19] "V6_two"       "V6_four"      "V5_std"       "V9_front"     "V20"          "V15_rotor"   
#[25] "V18_4bbl"

dim(carros)
#[1] 205  54

#Conjunto de atributos
setdiff(names(carros), names(carros_atributos[altamente_corr]))

carros <- carros[, setdiff(names(carros), names(carros_atributos[altamente_corr]))]

dim(carros)
#[1] 205  29

# Verificando se agora, depois de reduzir as dimensões, existem exemplos repetidos
dim(unique(carros))
#[1] 150  29

# Desconsiderando exemplos repetidos
carros <- unique(carros)




```

## Análises

Após as implementações escreva uma análise da base de dados. Em especial, descreva o conjunto de dados inicial, relate como foi realizado o tratamento, liste quais os atributos escolhidos para manter na base e descreva a base de dados após os tratamentos listados. Explique todos os passos executados, mas sem copiar códigos na análise. Além disso justifique suas escolhas de tratamento nos dados faltantes e seleção de atributos.


**Resposta:** <!-- Escreva sua resposta abaixo -->
O conjunto de dados é composto por 205 objetos e 26 atributos referentes a diferentes carros e suas características. Como informado na Tabela 1 do enunciado do exercício, o primeiro atributo (que é do tipo inteiro) refere-se ao risco calculado associado à cada carro, e seu valor pode variar entre -3 (menor risco) e 3 (maior risco).

Primeiramente, observamos os dados de forma resumida, através da função `summary`. Notamos que alguns atributos tem o tipo divergente daqueles indicados na Tabela 1, que descreve o conjunto de dados; como é o caso dos atributos V2, V19, V20, V22, V23, e V25. Na descrição, todos estão indicados como numéricos, mas a função summary retornou este como sendo do tipo _character_, indicando que deve haver valores não numéricos que alteraram inteiramente o tipo do atributo.

Para corrigir esses valores incorretos, primeiro fizemos a conferência se havia algum valor "NA", o que nos retornou _false_. Olhando o conjunto de dados, nos atributos mencionados assim, notamos que apesar de não haver valores vazios ou "NA", havia, porém, valores iguais a "?", explicando porque alguns atributos numéricos estavam sendo tratados como caracteres. Para facilitar a manipulação, todos esses valores foram convertidos para NA, pois assim, pela função `summary`, poderemos obter o valor médio dos atributos e atribuir este valor para as observações faltantes.

Outro tratamento importante é a verificação de amostras duplicadas. Aplicamos a função `unique`, cuja finalidade é identificar apenas as amostras com valores únicos (ou seja, não repetidos) no conjunto de dados. Nesse momento não foram identificados nenhuma amostra duplicada e por este motivo mantivemos o conjunto de dados inicial.

Para fazer a seleção dos atributos, primeiro buscamos identificar aqueles em que havia muitos valores faltantes, pois esta variável pouco contribuiria para a análise. O atributo V2, por exemplo, apresenta 41 valores NAs (20% do total de observações), e por isso decidimos eliminá-lo. Em seguida, verificamos quantas observações possuiam NAs em qualquer um dos campos, o que nos levou a um total de 10 observações. Como essa quantia é pequena, em relação ao total (4,78%), decidimos substituir esses valores pelas respectivas médias dos atributos.

A etapa seguinte de seleção dos atributos consistia na identificação e remoção dos atributos redundantes, visto que isso permite reduzir a dimensionalidade do conjunto de dados e economizar processamento. Primeiramente transformamos todas as variáveis categóricas em variáveis numéricas pelo método one hot enconding, o que permitiu a utilização das mesmas no cálculo da matriz de correlação. A matriz de correlação tem o objetivo de identificar quais dos atributos são mais ou menos correlacionados com os demais, sendo, portanto, uma boa medida da redundância. Decidimos retirar do nosso conjunto de dados todos os atributos cuja correlação seja de no mínimo 50% em relação a um ou mais dos outros atributos. Esse corte permitiu que o número de atributos do nosso conjunto de dados fosse reduzido de 54 para 29.

Decidimos fazer a transformação de todas as variáveis não numéricas - ao invés de transformar apenas aquelas que julgávamos necessárias manter - para poder incluí-las na matriz de correlação e só então, a partir dessa matriz, termos um referencial de qual manteríamos ou não. Observando atentamente os atributos indicados como altamente correlacionados, notamos como alguns até poderiam ter sido eliminados desde o início, como é o caso do atributo v4 (fuel_type) e v18 (fuel_system), pois o segundo atributo é suficiente para obter informações a respeito do primeiro (correlação igual a 1). De qualquer forma, nossa decisão em fazer uma análise criteriosa da correlação, antes de remover qualquer atributo se deve ao fato de não termos conhecimento inicial sobre o universo analisado.

Por fim, decidimos checar novamente se após a redução dos atributos havia amostras repetidas e desta vez tivemos um resultado positivo: 55 amostras eram repetidas. Retirando-as, nosso conjunto de dados final ficou com 150 observações e 29 atributos.
<!-- Fim da resposta -->


# Atividade 2 -- Agrupamento com o $K$*-means*

Nesta atividade, você deverá agrupar os dados com o algoritmo $K$*-means* e utilizará duas métricas básicas para a escolha do melhor $K$: a soma de distâncias intra-cluster e o coeficiente de silhueta. 

**Implementações:** Nos itens a seguir você implementará a geração de gráficos para a análise das distâncias intra-cluster e do coeficiente de silhueta. Em seguida, você implementará o agrupamento dos dados processados na atividade anterior com o algoritmo $K$*-means* utilizando o valor de $K$ escolhido.  

a) *Gráfico \textsl{Elbow Curve}:* Construa um gráfico com a soma das distâncias intra-cluster para $K$ variando de $2$ a $30$.

```{r atv2a-code}
# Construindo um gráfico com as distâncias intra-cluster

# Selecionando somente os atributos de interesse
carros_scaled <- carros[,3:length(carros)]
# Normalizando os atributos numéricos (os 3 primeiros, já que os outros são one-hot-encoding)
carros_scaled[,1:3] <- scale(carros_scaled[,1:3])
df <- carros_scaled
df <- na.omit(df)

# Determina o numero de grupos
set.seed(123)
fviz_nbclust(df, kmeans, method="wss", k.max = 30)


```

b) *Gráfico da Silhueta:* Construa um gráfico com o valor da silhueta para $K$ variando de $2$ a $30$.

```{r atv2b-code}
# Construindo um gráfico com os valores da silhueta

# Determina o numero de grupos (medida de silhueta)
fviz_nbclust(df, kmeans, method="silhouette", k.max = 30)


```

c) *Escolha do $K$:* Avalie os gráficos gerados nos itens anteriores e escolha o melhor valor  de $K$ com base nas informações desses gráficos e na sua análise. Se desejar, use também a função `NbClust` para ajudar nas análises. Com o valor de $K$ definido, utilize o rótulo obtido para cada amostra, indicando o grupo ao qual ela pertence, para gerar um gráfico de dispersão (atribuindo cores diferentes para cada grupo).

```{r atv2c-code}

# k escolhido: 2
# Justificativa: Pelo gráfico Elbow Curve, não é possível determinar um k ótimo, mas 
# nos mostra vários candidatos, como 2, 3, 6, 7, etc. Já o gráfico de silhueta nos dá como 
# a melhor k o 2.

# Aplicando o k-means com o k escolhido 
km.res <- eclust(carros_scaled, "kmeans", k=2, nstart=25, graph=FALSE)

# Construindo um gráfico de dispersão

  # versao 1
fviz_cluster(km.res, geom="point", frame.type="norm") + 
  ggtitle("k = 2") + theme_minimal()

  # versao 2: tentativa de saber quem eram os carros
#fviz_cluster(km.res, geom="point", data =carros_scaled, shape = 16) + 
#  geom_point(aes(shape = as.factor(carros$V3)), alpha = 0.5) + 
#  ggtitle("k = 2") + theme_minimal()

  # versao 3: tentativa de saber quem eram os symboling
#fviz_cluster(km.res, geom="point", data =carros_scaled, shape = 16) + 
#  geom_point(aes(shape = as.factor(carros$V1)), alpha = 0.5) + 
#  ggtitle("k = 2") + theme_minimal()

#fviz_cluster(km.res, geom="point", ellipse.type="norm", data =carros_scaled, shape = 16) + 
#  geom_point(aes(shape = as.factor(carros$V1)), alpha = 0.5) + 
#  ggtitle("k = 2") + theme_minimal()


```

## Análises

Descreva cada um dos gráficos gerados nos itens acima e analise-os. Inclua na sua análise as informações mais importantes que podemos retirar desses gráficos. Discuta sobre a escolha do valor $K$ e sobre a apresentação dos dados no gráfico de dispersão. 


**Resposta:** <!-- Escreva sua resposta abaixo -->


<!-- Fim da resposta -->

# Atividade 3 -- Agrupamento com o *DBscan*

Nesta atividade, você deverá agrupar os dados com o algoritmo *DBscan*. Para isso será necessário experimentar com diferentes valores de *eps* e *minPts*. 

a) *Ajuste de Parâmetros:* Experimente com valores diferentes para os parâmetros *eps* e *minPts*. Verifique o impacto dos diferentes valores nos agrupamentos.

```{r atv3a-code}

dados <- carros_scaled
set.seed(123)

# Executa algoritmo de agrupamentos DBSCAN

# Experimento com valores de eps e minPts

#densidade=1.0, obtemos muitos outliers
dbscan::dbscan(dados, eps=1.0, minPts=2)
dbscan::dbscan(dados, eps=1.0, minPts=3)
dbscan::dbscan(dados, eps=1.0, minPts=5)
dbscan::dbscan(dados, eps=1.0, minPts=8)

#densidade=1.5, obtemos menos outliers, 
dbscan::dbscan(dados, eps=1.5, minPts=2)
dbscan::dbscan(dados, eps=1.5, minPts=3)
dbscan::dbscan(dados, eps=1.5, minPts=5)
dbscan::dbscan(dados, eps=1.5, minPts=8)
dbscan::dbscan(dados, eps=1.5, minPts=13)

#densidade=2.0, começa a englobar conforme aumenta minPts, mas ainda com outliers
dbscan::dbscan(dados, eps=2.0, minPts=2)
dbscan::dbscan(dados, eps=2.0, minPts=3)
dbscan::dbscan(dados, eps=2.0, minPts=5)
dbscan::dbscan(dados, eps=2.0, minPts=8)
dbscan::dbscan(dados, eps=2.0, minPts=13)
  #minPts=3, 5 ou 8, ficam poucos de fora

#abaixo densidade para 2.5, engloba todos e tem k=2 para qualquer minPts
dbscan::dbscan(dados, eps=2.5, minPts=2)
dbscan::dbscan(dados, eps=2.5, minPts=3)
dbscan::dbscan(dados, eps=2.5, minPts=5)
dbscan::dbscan(dados, eps=2.5, minPts=8)
dbscan::dbscan(dados, eps=2.5, minPts=13)

# CONCLUSAO: minPts com 3 e 5 parecem bons => decidimos por minPts=5

#TODO: o que eh um bom minPts?

#

```

b) *Determinando Ruídos:* Escolha o valor de *minPts* que obteve o melhor resultado no item anterior e use a função `kNNdistplot` do pacote `dbscan` para determinar o melhor valor de *eps* para esse valor de *minPts*. Lembre-se que o objetivo não é remover todos os ruídos. 

```{r atv3b-code}
# Encontrando o melhor eps com o kNNdistplot
dbscan::kNNdistplot(dados, k = 5)

#CONCLUSAO: eps=1.9, analisando o grafico pelo "cotovelo"

```

c) *Visualizando os Grupos:* Após a escolha dos parâmetros *eps* e *minPts*, utilize o rótulo obtido para cada amostra, indicando o grupo ao qual ela pertence, para gerar um gráfico de dispersão (atribuindo cores diferentes para cada grupo).

```{r atv3c-code}
# Aplicando o DBscan com os parâmetros escolhidos
db <- dbscan::dbscan(dados, eps=1.9, minPts=5)

# Construindo um gráfico de dispersão
fviz_cluster(db, data=dados, stand=FALSE, 
             ellipse=FALSE, show.clust.cent=FALSE, 
             geom="point", palette="jco",
             ggtheme=theme_classic())

```

## Análises

Descreva os experimentos feitos para a escolha dos parâmetros *eps* e *minPts*. Inclua na sua análise as informações mais importantes que podemos retirar dos gráficos gerados. Justifique a escolha dos valores dos parâmetros e analise a apresentação dos dados no gráfico de dispersão. 


**Resposta:** <!-- Escreva sua resposta abaixo -->


<!-- Fim da resposta -->

# Atividade 4 -- Comparando os Algoritmos

<!-- Use o espaço abaixo para escrever os códigos necessários 
	para responder as perguntas a seguir  -->

```{r atv4-code}

```

Com base nas atividades anteriores, faça uma conclusão dos seus experimentos respondendo às seguintes perguntas: 

a) Qual dos métodos apresentou melhores resultados? Justifique.

b) Quantos agrupamentos foram obtidos?

c) Analisando o campo `symboling` e o grupo designado para cada amostra, os agrupamentos conseguiram separar os níveis de risco?

d) Analisando o campo `make` que contém as marcas dos carros, os agrupamentos conseguiram separar as marcas?


**Respostas:** <!-- Escreva sua resposta abaixo -->


<!-- Fim da resposta -->




